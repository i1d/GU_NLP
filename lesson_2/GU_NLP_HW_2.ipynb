{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUotKHRULVPD"
      },
      "source": [
        "# Инструменты для работы с языком "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ba5Z02VLVPK"
      },
      "source": [
        "## Задача: классификация твитов по тональности\n",
        "\n",
        "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
        "\n",
        "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zHB70n5LVPN",
        "outputId": "75b77f51-a19f-4c6d-b521-e46acd6e83a8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-06 09:29:25--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
            "--2022-05-06 09:29:25--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc64f8f0ad36634006bd472247c.dl.dropboxusercontent.com/cd/0/inline/Bku6yzmGV0oHNfaOaAgq9JKZRYDu8FMx1Iih-srmQ5twsFsDrHeLJekWN2aedfBiAsp8N5uU99_EX798t-ODYh2ptUTAnvRigMjkZoqRggohrZ17CCyP5ssqV7sHvK-OFIOunlzA3J2yopG0CrIByuMeWZiirOhHjvk3zH0EfefMBA/file# [following]\n",
            "--2022-05-06 09:29:26--  https://ucc64f8f0ad36634006bd472247c.dl.dropboxusercontent.com/cd/0/inline/Bku6yzmGV0oHNfaOaAgq9JKZRYDu8FMx1Iih-srmQ5twsFsDrHeLJekWN2aedfBiAsp8N5uU99_EX798t-ODYh2ptUTAnvRigMjkZoqRggohrZ17CCyP5ssqV7sHvK-OFIOunlzA3J2yopG0CrIByuMeWZiirOhHjvk3zH0EfefMBA/file\n",
            "Resolving ucc64f8f0ad36634006bd472247c.dl.dropboxusercontent.com (ucc64f8f0ad36634006bd472247c.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to ucc64f8f0ad36634006bd472247c.dl.dropboxusercontent.com (ucc64f8f0ad36634006bd472247c.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26233379 (25M) [text/plain]\n",
            "Saving to: ‘positive.csv’\n",
            "\n",
            "positive.csv        100%[===================>]  25.02M  71.8MB/s    in 0.3s    \n",
            "\n",
            "2022-05-06 09:29:26 (71.8 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
            "\n",
            "--2022-05-06 09:29:26--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
            "--2022-05-06 09:29:27--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc670842bb3fabb25c47f4a64803.dl.dropboxusercontent.com/cd/0/inline/BksNFTZ14BTs8hRRY1mmm53SlKmG-4qii1pfBcGmQApBM_3yxy4PBx3jbxTFn2OeVemtwXgyZm1e2T98Lb6BGmMYuZO9XT1tv-ybyBg1Nmkt95WtCbze8Q7J3eailEG19i1vKIA4EsS4pDQhUG5JnvFnfleh3xy6DeCtPuG-4hDMeg/file# [following]\n",
            "--2022-05-06 09:29:27--  https://uc670842bb3fabb25c47f4a64803.dl.dropboxusercontent.com/cd/0/inline/BksNFTZ14BTs8hRRY1mmm53SlKmG-4qii1pfBcGmQApBM_3yxy4PBx3jbxTFn2OeVemtwXgyZm1e2T98Lb6BGmMYuZO9XT1tv-ybyBg1Nmkt95WtCbze8Q7J3eailEG19i1vKIA4EsS4pDQhUG5JnvFnfleh3xy6DeCtPuG-4hDMeg/file\n",
            "Resolving uc670842bb3fabb25c47f4a64803.dl.dropboxusercontent.com (uc670842bb3fabb25c47f4a64803.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6022:15::a27d:420f\n",
            "Connecting to uc670842bb3fabb25c47f4a64803.dl.dropboxusercontent.com (uc670842bb3fabb25c47f4a64803.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24450101 (23M) [text/plain]\n",
            "Saving to: ‘negative.csv’\n",
            "\n",
            "negative.csv        100%[===================>]  23.32M  88.6MB/s    in 0.3s    \n",
            "\n",
            "2022-05-06 09:29:27 (88.6 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
        "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
        "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J5YiZNCPLVPe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DFLtXAZ-LVPq"
      },
      "outputs": [],
      "source": [
        "# считываем данные и заполняем общий датасет\n",
        "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "positive['label'] = ['positive'] * len(positive)\n",
        "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
        "negative['label'] = ['negative'] * len(negative)\n",
        "df = positive.append(negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j1AEISlBLVP0",
        "outputId": "3d03dd63-b1d2-4058-9b8c-0019f07da834"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     label\n",
              "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
              "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
              "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
              "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
              "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af356384-c7fc-47b1-9598-bdd50464c725\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>111918</th>\n",
              "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111919</th>\n",
              "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111920</th>\n",
              "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111921</th>\n",
              "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111922</th>\n",
              "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af356384-c7fc-47b1-9598-bdd50464c725')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af356384-c7fc-47b1-9598-bdd50464c725 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af356384-c7fc-47b1-9598-bdd50464c725');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZWta7oDgLVP8"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAapBC7VLVQC"
      },
      "source": [
        "## Baseline: классификация необработанных n-грамм\n",
        "\n",
        "### Векторизаторы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M-AvVt8XLVQD"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSuoVoxcLVQI"
      },
      "source": [
        "Что такое n-граммы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zeNA7732LVQJ"
      },
      "outputs": [],
      "source": [
        "from nltk import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeApDOmrLVQN",
        "outputId": "398bbb3c-37ef-46f2-ba66-5348d8598fb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sent = 'Если б мне платили каждый раз'.split()\n",
        "list(ngrams(sent, 1)) # униграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPAS0fS-LVQQ",
        "outputId": "8f16531b-92bd-49d7-efcf-89daaa80dc83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б'),\n",
              " ('б', 'мне'),\n",
              " ('мне', 'платили'),\n",
              " ('платили', 'каждый'),\n",
              " ('каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "list(ngrams(sent, 2)) # биграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d77jmVPhLVQU",
        "outputId": "db4cb919-95cf-4121-bf65-4da1e97f5fc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне'),\n",
              " ('б', 'мне', 'платили'),\n",
              " ('мне', 'платили', 'каждый'),\n",
              " ('платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "list(ngrams(sent, 3)) # триграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xXTBrGELVQX",
        "outputId": "3945d52e-3e22-4517-c723-17da24507f76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
              " ('б', 'мне', 'платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "list(ngrams(sent, 5)) # ... пентаграммы?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHGJBEm-LVQb"
      },
      "source": [
        "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
        "\n",
        "Объект `CountVectorizer` делает простую вещь:\n",
        "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
        "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eMqZFBTgLVQb"
      },
      "outputs": [],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZkpqVtILVQe"
      },
      "source": [
        "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
        "ngram_range=(1, 1) -- униграммы<br/>\n",
        "ngram_range=(3, 3) -- триграммы<br/>\n",
        "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
        "\n",
        "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWRtOSzKLVQf",
        "outputId": "9453fee9-04eb-4fba-ce14-c1b1502f0e3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i_love_on_di_de', 38561),\n",
              " ('люблю', 154302),\n",
              " ('тебяяяя', 220594),\n",
              " ('послала', 189848),\n",
              " ('его', 129806),\n",
              " ('пу', 198151),\n",
              " ('http', 37993),\n",
              " ('co', 21524),\n",
              " ('0azb1ark5c', 204),\n",
              " ('zirconium12', 96652)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "list(vec.vocabulary_.items())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkmX3iBbLVQi",
        "outputId": "1c6d5542-5f8f-46e4-aa0a-342c3df0b7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ8q5_59LVQm",
        "outputId": "3331ee8b-7f71-4ddb-a9d7-af283733bd33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.76      0.76     27988\n",
            "    positive       0.77      0.77      0.77     28721\n",
            "\n",
            "    accuracy                           0.77     56709\n",
            "   macro avg       0.77      0.77      0.77     56709\n",
            "weighted avg       0.77      0.77      0.77     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAhgaYgqLVQp"
      },
      "source": [
        "Попробуем сделать то же самое для триграмм:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPWXlh6ALVQq",
        "outputId": "73e5d562-a0cc-403e-ecb5-0351579a6f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.47      0.72      0.57     18293\n",
            "    positive       0.82      0.62      0.70     38416\n",
            "\n",
            "    accuracy                           0.65     56709\n",
            "   macro avg       0.65      0.67      0.64     56709\n",
            "weighted avg       0.71      0.65      0.66     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(3, 3))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnfyJkzTLVQu"
      },
      "source": [
        "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJABxhalLVQu"
      },
      "source": [
        "## TF-IDF векторизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LJES2s-LVQv"
      },
      "source": [
        "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
        "\n",
        "Как считается tf-idf:\n",
        "\n",
        "TF (term frequency) – относительная частотность слова в документе:\n",
        "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
        "\n",
        "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
        "\n",
        "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
        "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
        "\n",
        "`t` -- слово (term), `D` -- коллекция документов\n",
        "\n",
        "Перемножаем их:\n",
        "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
        "\n",
        "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
        "количестве документов, у него высокий TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FmEcRD28LVQ0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWLhMl9xLVQ3",
        "outputId": "92775320-9c2a-43eb-872e-7db231e3004a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.74      0.77      0.75     26764\n",
            "    positive       0.79      0.76      0.77     29945\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTODTRnKLVQ6"
      },
      "source": [
        "В этот раз получилось хуже :( Вернёмся к `CountVectorizer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8v9Scpn9Y0M"
      },
      "source": [
        "## PMI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRqLcSY0etj"
      },
      "source": [
        "Можно оценить взаимосвязь слов в корпусе и понять, какие биграммы наиболее часто встречаются в тексте. Для этого можно использовать метрику PMI (Pointwise Mutual Information) - поточечная взаимная информация. Метрика PMI для двух слов вычисляется по формуле:\n",
        "\n",
        "$$pmi(x; y) = log \\frac{p(x,y)}{p(x)p(y)} $$\n",
        "\n",
        "Здесь p(y|x) - вероятность встретить слово $y$ после $x$, $p(y)$ - вероятность встретить слово $y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXgDwf6W6Kk5"
      },
      "source": [
        "Оценим важность биграмм в нашем обучающем корпусе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKmiOEaW53F9",
        "outputId": "764f2522-9b91-4f19-bf1f-b212b45cebb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
            "[('***ТЫ', 'ЛАПОЧКА'), ('***ахах', 'Ксююю'), ('***сегодня', 'ироска'), ('*FUCK', 'ЛОГИК*'), ('*__________________*', 'вообщеееееееее'), ('*blog', 'Трансформация'), ('*facepalm.jpg*', 'Ебанные'), ('*happy', 'tree*'), ('*linux', '*arch'), ('*°•', '•●♥'), ('*ВЕЧНАЯ', 'ПАМЯТЬ*'), ('*Кукэева', 'минем**Лучшая'), ('*Мне', 'отвёртку'), ('*Оля', 'Фадеева'), ('*ПОТЕКЛИ', 'СЛЮНИ*'), ('*СЛЕЗЫ', 'СЛЕЗЫ*'), ('*аалгах', 'гээх'), ('*барабанная', 'дробь*'), ('*без', 'намёков*'), ('*белая', 'зависть*'), ('*возможную', 'дочь*-*прости'), ('*вот', 'зараза*'), ('*вспоминаю', 'евоные'), ('*вчера', 'перечитывал'), ('*вытирает', 'стекающий'), ('*гениальный', 'вопрос*'), ('*громко', 'смеется*'), ('*довольная', 'ангарская'), ('*ещё', 'глаток*'), ('*здесь*-это', '*куда*'), ('*ирный', 'у*людок'), ('*к', 'зайцу*Олли'), ('*коварная', 'мысль*'), ('*ленивая', 'жопа*'), ('*лучи', 'отдыха*'), ('*мастер', 'отмазок*'), ('*мое', 'мнение*'), ('*на', 'уроке*'), ('*не', 'реклама*'), ('*нормальным', 'голосом*Лен'), ('*обнимаю', 'монитор*'), ('*опустил', 'голову*'), ('*опять', 'реву*'), ('*палец', 'вверх*'), ('*поймал', 'одеялком*'), ('*пока', 'что*'), ('*положил', 'книгу*'), ('*придирчиво', 'оглядывает*'), ('*сатанинский', 'хохот*'), ('*свои', 'мысли*'), ('*сладких', 'чуу'), ('*смотрю', 'клип*'), ('*сырая', 'еще*'), ('*такая', 'милая:3333авввв'), ('*тихим', 'голосом*'), ('*тихо', 'застонала*'), ('*фууф', 'отстрелялись*'), ('*хитрый', 'взгляд*'), ('*широких', 'поясах*'), ('+1239', '728'), ('+375447167151', 'звоги'), ('+Никита', '=полностью'), ('+СОННО', '+НЕ'), ('+живіт', 'болить.ну'), ('+погода', 'крутая='), (',4', 'запирайте'), (',Дела', 'рез'), ('-*..как', 'делиФФки'), ('-10,11', 'болсо'), ('-163', '-КРАСНЫЙ'), ('-165', '-СИНИЙ'), ('-29..', 'ПФ'), ('-53', 'dBm'), ('-700', 'рублей.-А'), ('-800', 'нахууй'), ('-Dдаа..', 'Встречала'), ('-АХАХАХАХ', 'ЮБКУ'), ('-АХАХАХАХХАХАХАХАХАХХА', '-АХАХАХХАХАХАХАХАХ'), ('-Алина', '-Синие'), ('-Аха', 'спетросянил'), ('-ВАХАХАХА', 'СТИПЕНДИЯ'), ('-ВСЕМ', 'СПОКОЙНЫХ'), ('-Вам', 'завернуть'), ('-Время', 'эмокора'), ('-Выздоравливай', 'педрилк'), ('-ГНИДОТА', '-Над'), ('-Д-Д-Д-Д-Д-Д-ДРОП', 'ЗЭ'), ('-ДЕТЕЙ', 'НАКРЫЛО'), ('-ДОВАЙТИ', 'АЛДСКУЛ'), ('-Домашка', '-кл.час'), ('-ЖАРЕНЫЙ', 'КАРТОФЕЛЬ'), ('-ЗАШЛА', 'ОДЕЛА'), ('-Защитано', '-ес'), ('-Зелено-карие', '-Киллджой'), ('-КРАСНЫЙ', '-ЧЕРНЫЕ'), ('-Керем', 'севгили'), ('-Киллджой', '-Котик'), ('-МАРИЯ', '-МИША'), ('-Маладец', '-Лол'), ('-Мамаааа', 'поправь')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import collocations \n",
        "nltk.download('genesis')\n",
        "nltk.download('punkt')\n",
        "\n",
        "print(type(nltk.corpus.genesis.words('english-web.txt')))\n",
        "bigram_measures = collocations.BigramAssocMeasures()\n",
        "# bigram_finder.apply_freq_filter(5)\n",
        "bigram_finder = collocations.BigramCollocationFinder.from_documents([nltk.word_tokenize(x) for x in x_train])\n",
        "bigrams = bigram_finder.nbest(bigram_measures.pmi, 100)\n",
        "print(bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h4Cq1PUTTc-"
      },
      "source": [
        "Можно рассмотреть другие метрики оценки важности биграмм, например, метрику правдоподобия (подробнее про вычисление метрики можно посмотреть [здесь (пункт 5.3.4)](http://www.corpus.unam.mx/cursoenah/ManningSchutze_1999_FoundationsofStatisticalNaturalLanguageProcessing.pdf):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTOJg4KoOo84",
        "outputId": "f50bd584-d74a-4291-a50a-fdac6813a01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('(', '('), ('RT', '@'), (')', ')'), ('http', ':'), ('!', '!'), (':', 'D'), ('у', 'меня'), (':', '('), (',', 'а'), (',', 'что'), (',', 'но'), (')', 'http'), ('у', 'нас'), ('(', ','), (':', ')'), (':', '-'), (',', '('), (',', ')'), ('?', '?'), ('не', 'могу'), (':', '*'), (')', ','), (',', ':'), ('@', '('), (',', ','), (':', ','), ('(', ':'), ('@', ')'), ('@', ','), ('&', 'lt'), ('со', 'мной'), ('@', ':'), ('(', '@'), (':', ':'), ('gt', ';'), (';', ')'), ('новый', 'год'), (',', '@'), (')', ':'), ('не', 'знаю'), ('@', '@'), ('а', 'я'), (',', 'когда'), ('У', 'меня'), ('потому', 'что'), ('lt', ';'), ('сих', 'пор'), ('&', 'gt'), (';', '('), ('все', 'равно'), ('у', 'тебя'), (',', 'как'), ('с', 'тобой'), ('в', 'школу'), ('(', 'http'), (',', 'я'), (')', '@'), ('ничего', 'не'), ('-', ')'), (':', 'DD'), ('&', 'amp'), ('я', 'не'), ('Как', 'же'), ('Доброе', 'утро'), ('не', '('), ('самом', 'деле'), ('не', ')'), ('что', 'я'), ('(', '!'), (',', '!'), ('--', '--'), ('D', 'http'), ('до', 'сих'), ('об', 'этом'), (',', 'чтобы'), ('.', 'А'), ('не', ':'), ('amp', ';'), ('никто', 'не'), ('!', ','), ('=', ')'), ('как', 'же'), (':', '!'), ('с', 'кем'), (',', '.'), ('?', '—'), (':', '|'), ('.', ','), ('и', ')'), ('никогда', 'не'), ('а', 'потом'), (':', '.'), ('@', 'не'), ('не', '@'), ('.', 'Но'), ('#', 'євромайдан'), ('Новый', 'Год'), ('@', '!'), ('в', 'школе'), ('в', 'этом')]\n"
          ]
        }
      ],
      "source": [
        "bigrams = bigram_finder.nbest(bigram_measures.likelihood_ratio, 100)\n",
        "print(bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfjCYZa8TeX_"
      },
      "source": [
        "Как можно заметить, немаловажную роль в текстах занимает пунктуация."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AJk1B39LVRP"
      },
      "source": [
        "## Стоп-слова и пунктуация\n",
        "\n",
        "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpWhsTuRLVRP",
        "outputId": "a90ed033-d859-42da-fce1-6370c664e814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
          ]
        }
      ],
      "source": [
        "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "print(stopwords.words('russian'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OdRF7rlyLVRS",
        "outputId": "37768e94-0748-4756-a7af-6234048740b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from string import punctuation\n",
        "punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OfXiH98XLVRV"
      },
      "outputs": [],
      "source": [
        "noise = stopwords.words('russian') + list(punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtiIhHDMLVRY"
      },
      "source": [
        "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZnbarm_LVRY",
        "outputId": "af2c0eed-bcb3-4315-806c-f4632e2fc4ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
            "  % sorted(inconsistent)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.76      0.78     29049\n",
            "    positive       0.76      0.80      0.78     27660\n",
            "\n",
            "    accuracy                           0.78     56709\n",
            "   macro avg       0.78      0.78      0.78     56709\n",
            "weighted avg       0.78      0.78      0.78     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize, stop_words=noise)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr934O7yLVRb"
      },
      "source": [
        "Получилось чууть лучше. Что ещё можно сделать?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7O_oD1fLVRc"
      },
      "source": [
        "## Лемматизация\n",
        "\n",
        "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
        "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
        "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
        "\n",
        "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
        "\n",
        "### [Mystem](https://tech.yandex.ru/mystem/)\n",
        "Как с ним работать:\n",
        "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
        "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96HdoB7zLVRc",
        "outputId": "2c0d0ec7-89b6-416f-94de-d0930a0e3451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-06 09:33:01--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.242, 5.45.205.244, 5.45.205.245, ...\n",
            "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.242|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cachev2-mskm914.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=235 [following]\n",
            "--2022-05-06 09:33:02--  https://cachev2-mskm914.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=235\n",
            "Resolving cachev2-mskm914.cdn.yandex.net (cachev2-mskm914.cdn.yandex.net)... 5.45.220.114, 2a02:6b8:0:2002::925\n",
            "Connecting to cachev2-mskm914.cdn.yandex.net (cachev2-mskm914.cdn.yandex.net)|5.45.220.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16457938 (16M) [application/octet-stream]\n",
            "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz’\n",
            "\n",
            "mystem-3.0-linux3.1 100%[===================>]  15.70M  8.09MB/s    in 1.9s    \n",
            "\n",
            "2022-05-06 09:33:05 (8.09 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz’ saved [16457938/16457938]\n",
            "\n",
            "mystem\n"
          ]
        }
      ],
      "source": [
        "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!cp mystem /bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kzQwGwAaZWV5"
      },
      "outputs": [],
      "source": [
        "from pymystem3 import Mystem\n",
        "mystem_analyzer = Mystem()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w-_fkNtLVRf"
      },
      "source": [
        "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
        "* mystem_bin - путь к `mystem`, если их несколько\n",
        "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
        "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
        "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
        "\n",
        "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
        "\n",
        "Можно просто лемматизировать текст:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjHHLQv9txDq",
        "outputId": "4b310032-740e-4d84-abe2-a69dddcb19ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', ' ', 'is', ' ', 'text', '\\n']\n"
          ]
        }
      ],
      "source": [
        "example = 'this is text'\n",
        "print(mystem_analyzer.lemmatize(example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI1eftjkLVRi"
      },
      "source": [
        "А можно получить грамматическую информацию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "j4MLqlZnxNEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc32177e-d1f9-4d36-bbb8-a515d5254160"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'analysis': [], 'text': 'this'},\n",
              " {'text': ' '},\n",
              " {'analysis': [], 'text': 'is'},\n",
              " {'text': ' '},\n",
              " {'analysis': [], 'text': 'text'},\n",
              " {'text': '\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "mystem_analyzer.analyze(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADcGtz4JLVRl"
      },
      "source": [
        "Давайте терепь используем лемматизатор майстема в качестве токенизатора."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "x48Q56tiLVRn"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def my_preproc(text):\n",
        "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
        "    text = mystem_analyzer.lemmatize(text)\n",
        "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wEwOQTJPLVRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f64c7c8-9a5e-4396-cd7a-bac33cc60d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.74      0.76     29179\n",
            "    positive       0.74      0.77      0.75     27530\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJlvqWuALVRs"
      },
      "source": [
        "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
        "Это модуль на питоне, довольно быстрый и с кучей функций."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tHDkurN1zf7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3be94f-1bbf-4327-9668-f19a64925f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7SlwsLU7LVRt"
      },
      "outputs": [],
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "pymorphy2_analyzer = MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qaz0x7frLVRw"
      },
      "source": [
        "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jdf6XoEbLVRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11aa156-354f-4bd3-f445-957ec7ef00e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "ana = pymorphy2_analyzer.parse(sent[3])\n",
        "ana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0KuHQGPgLVRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97e60b82-27e0-4568-badc-2058b6d9d702"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'платить'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "ana[0].normal_form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gg0EASPcLVR8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFTkF8xUARlS"
      },
      "source": [
        "### [Natasha](https://github.com/natasha/)\n",
        "\n",
        "В библиотеке natasha реализовано множество полезных библиотек для русского языка: разбиение на токены и предложения, русскоязычные word embeddings, морфологический, синтаксический анализ, лемматизация, извлечение именованных сущностей и т.д. Модуль библиотеки Razdel, основанный на правилах, предназначен для разбиения текста на токены и предложения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-CVeDxeIA6rg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0a72f3-5279-41d3-f1b2-86ec93f75a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MOTkw9MpAnNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524a541b-c409-487f-959c-1da014e44056"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 13, 'Кружка-термос'),\n",
              " Substring(14, 16, 'на'),\n",
              " Substring(17, 20, '0.5'),\n",
              " Substring(20, 21, 'л'),\n",
              " Substring(22, 23, '('),\n",
              " Substring(23, 28, '50/64'),\n",
              " Substring(29, 32, 'см³'),\n",
              " Substring(32, 33, ','),\n",
              " Substring(34, 37, '516'),\n",
              " Substring(37, 38, ';'),\n",
              " Substring(38, 41, '...'),\n",
              " Substring(41, 42, ')')]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "from razdel import tokenize\n",
        "\n",
        "tokens = list(tokenize('Кружка-термос на 0.5л (50/64 см³, 516;...)'))\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Ftx-WzUbBCpO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ab56a4-483d-416a-e3f6-dc92c46d309f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Кружка-термос',\n",
              " 'на',\n",
              " '0.5',\n",
              " 'л',\n",
              " '(',\n",
              " '50/64',\n",
              " 'см³',\n",
              " ',',\n",
              " '516',\n",
              " ';',\n",
              " '...',\n",
              " ')']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "[_.text for _ in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "uyhsQp4MGbW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9738c32f-9254-4645-848c-92e14df518a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natasha\n",
            "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 86 kB/s \n",
            "\u001b[?25hRequirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Collecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
            "Collecting slovnet>=0.3.0\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 91 kB/s \n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.21.6)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=0f4433232b3e2083195b6435ac9b2ee66a6d2833513ff4ca1bf3874e48ef8652\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 slovnet-0.5.0 yargy-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install natasha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMO3jsqLKSIV"
      },
      "source": [
        "С помощью библиотеки natasha можно также лемматизировать тексты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vJZgfRnvIS2q"
      },
      "outputs": [],
      "source": [
        "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger\n",
        "\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "\n",
        "def natasha_lemmatize(text):\n",
        "  doc = Doc(text)\n",
        "  doc.segment(segmenter)\n",
        "  doc.tag_morph(morph_tagger)\n",
        "  for token in doc.tokens:\n",
        "    token.lemmatize(morph_vocab)\n",
        "  return {_.text: _.lemma for _ in doc.tokens}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iBtlnYlFBOKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4dac10e-b1be-48a6-f22c-a389c198d9da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(': '(',\n",
              " ')': ')',\n",
              " ',': ',',\n",
              " '.': '.',\n",
              " '1': '1',\n",
              " '11': '11',\n",
              " '110-летия': '110-летие',\n",
              " '1909': '1909',\n",
              " '1909-1959': '1909-1959',\n",
              " '2010': '2010',\n",
              " '2019': '2019',\n",
              " 'Twitter': 'twitter',\n",
              " '«': '«',\n",
              " '»': '»',\n",
              " 'Бандера': 'бандера',\n",
              " 'Бандере': 'бандера',\n",
              " 'Бандеры': 'бандера',\n",
              " 'В': 'в',\n",
              " 'Верховной': 'верховный',\n",
              " 'Виктора': 'виктор',\n",
              " 'Героем': 'герой',\n",
              " 'Героя': 'герой',\n",
              " 'Житомирский': 'житомирский',\n",
              " 'Израиля': 'израиль',\n",
              " 'Йоэль': 'йоэль',\n",
              " 'Лион': 'лион',\n",
              " 'Львовский': 'львовский',\n",
              " 'Львовской': 'львовский',\n",
              " 'ОУН': 'оун',\n",
              " 'Организации': 'организация',\n",
              " 'Парламентарии': 'парламентарий',\n",
              " 'Петру': 'петр',\n",
              " 'Порошенко': 'порошенко',\n",
              " 'Посол': 'посол',\n",
              " 'Рады': 'рада',\n",
              " 'России': 'россия',\n",
              " 'Свое': 'свой',\n",
              " 'Степан': 'степан',\n",
              " 'Степана': 'степан',\n",
              " 'Украина': 'украина',\n",
              " 'Украине': 'украина',\n",
              " 'Украины': 'украина',\n",
              " 'Ющенко': 'ющенко',\n",
              " 'Я': 'я',\n",
              " 'а': 'а',\n",
              " 'аналогичное': 'аналогичный',\n",
              " 'антисемитизмом': 'антисемитизм',\n",
              " 'антисемитских': 'антисемитский',\n",
              " 'бороться': 'бороться',\n",
              " 'борьбе': 'борьба',\n",
              " 'был': 'быть',\n",
              " 'было': 'быть',\n",
              " 'в': 'в',\n",
              " 'вернуть': 'вернуть',\n",
              " 'властей': 'власть',\n",
              " 'впоследствии': 'впоследствии',\n",
              " 'выступающей': 'выступать',\n",
              " 'героем': 'герой',\n",
              " 'год': 'год',\n",
              " 'года': 'год',\n",
              " 'годом': 'год',\n",
              " 'году': 'год',\n",
              " 'государства': 'государство',\n",
              " 'декабря': 'декабрь',\n",
              " 'депутаты': 'депутат',\n",
              " 'деятельностью': 'деятельность',\n",
              " 'дипломат': 'дипломат',\n",
              " 'дня': 'день',\n",
              " 'должна': 'должный',\n",
              " 'евреев': 'еврей',\n",
              " 'за': 'за',\n",
              " 'забывать': 'забывать',\n",
              " 'запрещенной': 'запретить',\n",
              " 'заявление': 'заявление',\n",
              " 'звание': 'звание',\n",
              " 'и': 'и',\n",
              " 'из': 'из',\n",
              " 'информационном': 'информационный',\n",
              " 'исполнителей': 'исполнитель',\n",
              " 'их': 'они',\n",
              " 'июле': 'июль',\n",
              " 'к': 'к',\n",
              " 'как': 'как',\n",
              " 'ксенофобией': 'ксенофобия',\n",
              " 'кто': 'кто',\n",
              " 'лидера': 'лидер',\n",
              " 'лидеров': 'лидер',\n",
              " 'месяца': 'месяц',\n",
              " 'мифов': 'миф',\n",
              " 'могу': 'мочь',\n",
              " 'на': 'на',\n",
              " 'написал': 'написать',\n",
              " 'населением': 'население',\n",
              " 'националистов': 'националист',\n",
              " 'национальным': 'национальный',\n",
              " 'начале': 'начало',\n",
              " 'не': 'не',\n",
              " 'независимого': 'независимый',\n",
              " 'непосредственно': 'непосредственно',\n",
              " 'никоим': 'никой',\n",
              " 'о': 'о',\n",
              " 'области': 'область',\n",
              " 'областной': 'областной',\n",
              " 'образом': 'образ',\n",
              " 'обратились': 'обратиться',\n",
              " 'объявить': 'объявить',\n",
              " 'однако': 'однако',\n",
              " 'одним': 'один',\n",
              " 'он': 'он',\n",
              " 'остановит': 'остановить',\n",
              " 'отменено': 'отменить',\n",
              " 'отмечать': 'отмечать',\n",
              " 'период': 'период',\n",
              " 'подрывной': 'подрывной',\n",
              " 'поле': 'поле',\n",
              " 'помогает': 'помогать',\n",
              " 'поможет': 'помочь',\n",
              " 'понять': 'понять',\n",
              " 'посмертно': 'посмертно',\n",
              " 'почитание': 'почитание',\n",
              " 'празднованием': 'празднование',\n",
              " 'предложением': 'предложение',\n",
              " 'президентства': 'президентство',\n",
              " 'президенту': 'президент',\n",
              " 'преступлениях': 'преступление',\n",
              " 'признался': 'признаться',\n",
              " 'признан': 'признать',\n",
              " 'признание': 'признание',\n",
              " 'принимал': 'принимать',\n",
              " 'принял': 'принять',\n",
              " 'пришел': 'прийти',\n",
              " 'провозгласить': 'провозгласить',\n",
              " 'пропагандой': 'пропаганда',\n",
              " 'прославление': 'прославление',\n",
              " 'против': 'против',\n",
              " 'разместил': 'разместить',\n",
              " 'распространение': 'распространение',\n",
              " 'регионе': 'регион',\n",
              " 'решение': 'решение',\n",
              " 'решении': 'решение',\n",
              " 'родился': 'родиться',\n",
              " 'рождения': 'рождение',\n",
              " 'российской': 'российский',\n",
              " 'с': 'с',\n",
              " 'связи': 'связь',\n",
              " 'со': 'с',\n",
              " 'совершенных': 'совершить',\n",
              " 'совет': 'совет',\n",
              " 'создание': 'создание',\n",
              " 'созданных': 'создать',\n",
              " 'страны': 'страна',\n",
              " 'судом': 'суд',\n",
              " 'также': 'также',\n",
              " 'территориях': 'территория',\n",
              " 'тех': 'тот',\n",
              " 'уверены': 'уверить',\n",
              " 'ужасных': 'ужасный',\n",
              " 'узнав': 'узнать',\n",
              " 'украиноязычным': 'украиноязычный',\n",
              " 'украинских': 'украинский',\n",
              " 'участие': 'участие',\n",
              " 'через': 'через',\n",
              " 'что': 'что',\n",
              " 'шок': 'шок',\n",
              " 'это': 'это',\n",
              " 'января': 'январь',\n",
              " '—': '—'}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "text = 'Посол Израиля на Украине Йоэль Лион признался, что пришел в шок, узнав о решении властей Львовской области объявить 2019 год годом лидера запрещенной в России Организации украинских националистов (ОУН) Степана Бандеры. Свое заявление он разместил в Twitter. «Я не могу понять, как прославление тех, кто непосредственно принимал участие в ужасных антисемитских преступлениях, помогает бороться с антисемитизмом и ксенофобией. Украина не должна забывать о преступлениях, совершенных против украинских евреев, и никоим образом не отмечать их через почитание их исполнителей», — написал дипломат. 11 декабря Львовский областной совет принял решение провозгласить 2019 год в регионе годом Степана Бандеры в связи с празднованием 110-летия со дня рождения лидера ОУН (Бандера родился 1 января 1909 года). В июле аналогичное решение принял Житомирский областной совет. В начале месяца с предложением к президенту страны Петру Порошенко вернуть Бандере звание Героя Украины обратились депутаты Верховной Рады. Парламентарии уверены, что признание Бандеры национальным героем поможет в борьбе с подрывной деятельностью против Украины в информационном поле, а также остановит «распространение мифов, созданных российской пропагандой». Степан Бандера (1909-1959) был одним из лидеров Организации украинских националистов, выступающей за создание независимого государства на территориях с украиноязычным населением. В 2010 году в период президентства Виктора Ющенко Бандера был посмертно признан Героем Украины, однако впоследствии это решение было отменено судом. '\n",
        "\n",
        "natasha_lemmatize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rck5OVqhLVSA"
      },
      "source": [
        "### mystem vs. pymorphy vs. natasha\n",
        "\n",
        "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
        "\n",
        "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту, natasha тоже с этим тоже не справляется успешно:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "kH2GQ4ddLVSB"
      },
      "outputs": [],
      "source": [
        "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
        "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WwF-XsjeI3eX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf9c009-7e2e-4d8b-da55-686e9b6b34fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292578, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
            "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970059, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
          ]
        }
      ],
      "source": [
        "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
        "\n",
        "print(mystem_analyzer.analyze(homonym1)[-5])\n",
        "print(mystem_analyzer.analyze(homonym2)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "t9jezRVlFmDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b66ae9-3d3a-469f-85fd-315163c1d10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'За': 'за', 'время': 'время', 'обучения': 'обучение', 'я': 'я', 'прослушал': 'прослушать', 'больше': 'большой', 'сорока': 'сорок', 'курсов': 'курс', '.': '.'}\n"
          ]
        }
      ],
      "source": [
        "print(natasha_lemmatize(homonym1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "SXjGBQPoI9gl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19adc26-9459-4535-eb1f-7fbc6294ab40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Сорока': 'сорок', 'своровала': 'своровать', 'блестящее': 'блестящий', 'украшение': 'украшение', 'со': 'с', 'стола': 'стол', '.': '.'}\n"
          ]
        }
      ],
      "source": [
        "print(natasha_lemmatize(homonym2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP5qFnilLVSI"
      },
      "source": [
        "## Словарь, закон Ципфа и закон Хипса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1umtd3OLVSI"
      },
      "source": [
        "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "lY0cWJ7eLVSJ"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIjqSVjpLVSL",
        "outputId": "dd523631-f681-4ac3-8a58-1502753c1e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2859142\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "corpus = [token for tweet in df.text for token in nltk.word_tokenize(tweet) if token not in punctuation]\n",
        "print(len(corpus))\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "_oWC7NpkLVSO",
        "outputId": "b29965f6-2269-4573-f4db-9a8df6a7ce91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('не', 69267),\n",
              " ('и', 54916),\n",
              " ('в', 52853),\n",
              " ('я', 52506),\n",
              " ('RT', 38070),\n",
              " ('на', 35715),\n",
              " ('http', 32992),\n",
              " ('что', 31472),\n",
              " ('...', 28773),\n",
              " ('с', 27176)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
        "list(freq_dict_sorted)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FrPkce0SLVSQ",
        "outputId": "1fc9c7f4-38a5-4b78-842d-c8bdb9238f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
        "plt.plot(first_100_freqs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_N5V_K-LVSU"
      },
      "source": [
        "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0GieJSMU-O"
      },
      "source": [
        "## Задание 1.\n",
        "\n",
        "**Задание**: обучите три классификатора: \n",
        "\n",
        "1) на токенах с высокой частотой \n",
        "\n",
        "2) на токенах со средней частотой \n",
        "\n",
        "3) на токенах с низкой частотой\n",
        "\n",
        "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fds_hf = dict(sorted(freq_dict.items(), key=lambda x: -x[1])[:100])\n",
        "lst_hf = list(fds_hf.keys())\n",
        "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(lst_hf)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train[:100])\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY1ntHca7VwO",
        "outputId": "0fdafa6d-b70a-4ad7-8088-2a0f736f9ef6"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.66      0.48      0.55     38132\n",
            "    positive       0.31      0.49      0.38     18577\n",
            "\n",
            "    accuracy                           0.48     56709\n",
            "   macro avg       0.48      0.48      0.47     56709\n",
            "weighted avg       0.54      0.48      0.50     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "QUQ6kAgPMqNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f64f2b-126b-41f7-e243-f8643393f68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.49      0.66     56673\n",
            "    positive       0.00      0.61      0.00        36\n",
            "\n",
            "    accuracy                           0.49     56709\n",
            "   macro avg       0.50      0.55      0.33     56709\n",
            "weighted avg       1.00      0.49      0.66     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "fds_mf = dict(sorted(freq_dict.items(), key=lambda x: -x[1])[round(len(freq_dict)/2)-50:round(len(freq_dict)/2)+50])\n",
        "lst_mf = list(fds_mf.keys())\n",
        "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(lst_mf)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train[:100])\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fds_lf = dict(sorted(freq_dict.items(), key=lambda x: -x[1])[-100:])\n",
        "lst_lf = list(fds_lf.keys())\n",
        "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(lst_lf)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train[:100])\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAazFS989Rgu",
        "outputId": "c9be907c-0145-4354-aa5e-6ce5a16e3025"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.91      0.52      0.66     48795\n",
            "    positive       0.18      0.67      0.29      7914\n",
            "\n",
            "    accuracy                           0.54     56709\n",
            "   macro avg       0.55      0.60      0.47     56709\n",
            "weighted avg       0.81      0.54      0.61     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV3fmzp-LVSU"
      },
      "source": [
        "## О важности эксплоративного анализа\n",
        "\n",
        "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qjkMxK9VLVSV",
        "outputId": "65c7664d-4f66-462c-b5e9-6ae3c8a93b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00     27813\n",
            "    positive       1.00      1.00      1.00     28896\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2fRbUAvLVSX"
      },
      "source": [
        "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y7QNfKBIPrb"
      },
      "source": [
        "## Задание 2.\n",
        "\n",
        "найти фичи с наибольшей значимостью, и вывести их"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "DbwZ3Q3PIPrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca77518-1180-4c98-aca2-fbc37587281c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['не',\n",
              " 'и',\n",
              " 'в',\n",
              " 'я',\n",
              " 'RT',\n",
              " 'на',\n",
              " 'http',\n",
              " 'что',\n",
              " '...',\n",
              " 'с',\n",
              " 'а',\n",
              " 'меня',\n",
              " 'у',\n",
              " 'как',\n",
              " 'так',\n",
              " 'D',\n",
              " 'это',\n",
              " 'мне',\n",
              " 'все',\n",
              " 'ты',\n",
              " 'но',\n",
              " \"''\",\n",
              " 'Я',\n",
              " '``',\n",
              " 'то',\n",
              " 'по',\n",
              " 'уже',\n",
              " 'за',\n",
              " 'же',\n",
              " 'ну',\n",
              " 'А',\n",
              " 'только',\n",
              " 'бы',\n",
              " 'еще',\n",
              " 'да',\n",
              " 'вот',\n",
              " 'тебя',\n",
              " 'нет',\n",
              " 'когда',\n",
              " 'очень',\n",
              " 'к',\n",
              " 'будет',\n",
              " 'сегодня',\n",
              " 'день',\n",
              " 'хочу',\n",
              " 'он',\n",
              " 'просто',\n",
              " 'от',\n",
              " 'было',\n",
              " 'тебе',\n",
              " 'из',\n",
              " 'мы',\n",
              " 'И',\n",
              " 'тоже',\n",
              " '—',\n",
              " 'до',\n",
              " 'там',\n",
              " 'надо',\n",
              " 'даже',\n",
              " 'его',\n",
              " 'теперь',\n",
              " 'есть',\n",
              " 'вообще',\n",
              " 'если',\n",
              " 'для',\n",
              " 'о',\n",
              " 'нас',\n",
              " 'В',\n",
              " 'завтра',\n",
              " 'она',\n",
              " 'могу',\n",
              " 'Не',\n",
              " 'всё',\n",
              " 'Ну',\n",
              " 'буду',\n",
              " 'сейчас',\n",
              " 'У',\n",
              " 'Как',\n",
              " 'знаю',\n",
              " 'без',\n",
              " 'тут',\n",
              " 'раз',\n",
              " 'кто',\n",
              " 'они',\n",
              " 'или',\n",
              " 'люблю',\n",
              " 'больше',\n",
              " 'ничего',\n",
              " 'со',\n",
              " '2',\n",
              " 'про',\n",
              " 'вы',\n",
              " 'всегда',\n",
              " 'блин',\n",
              " 'Но',\n",
              " 'почему',\n",
              " 'можно',\n",
              " '3',\n",
              " 'С',\n",
              " 'чем']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "list(fds_hf.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vtAyItvLVSb"
      },
      "source": [
        "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "uqH07o-7LVSc",
        "outputId": "37572c35-7881-478b-8f67-2058db642b3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.47      0.44      0.45     29761\n",
            "    positive       0.42      0.45      0.43     26948\n",
            "\n",
            "    accuracy                           0.44     56709\n",
            "   macro avg       0.44      0.44      0.44     56709\n",
            "weighted avg       0.45      0.44      0.44     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cool_token = list(fds_hf.keys())[0]\n",
        "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5THCOjMLVSg"
      },
      "source": [
        "## Символьные n-граммы\n",
        "\n",
        "Теперь в качестве фичей используем, например, униграммы символов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "AIUwDOabLVSh",
        "outputId": "3159e72d-81a1-42a0-a441-0c998f73caf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.99      1.00      1.00     27723\n",
            "    positive       1.00      0.99      1.00     28986\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_E0uPpgLVSj"
      },
      "source": [
        "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
        "\n",
        "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.препроцессинг\n",
        "2.векторизация\n",
        "3.обучение классификатора (например, логистическая регрессия)\n"
      ],
      "metadata": {
        "id": "qYxG65eXBpE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "idf_ степерь важности признаков"
      ],
      "metadata": {
        "id": "jDWE9RjH9Vah"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5AJk1B39LVRP"
      ],
      "name": "GU_NLP_HW_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}